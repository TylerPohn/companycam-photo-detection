# Story 2.4: Volume Estimation Engine (P1)

**Status:** Ready for Development

---

## Story

**As a** Backend Developer,
**I want** to implement the Volume Estimation Engine that estimates volumes of loose materials (gravel, mulch, sand) using depth estimation and scale references,
**so that** contractors and project managers can quickly estimate material quantities for ordering and project planning.

---

## Acceptance Criteria

1. Depth estimation model (MiDaS/DPT) integrated for generating depth maps from single photos
2. Loose material detection and segmentation implemented to identify material boundaries
3. Scale reference detection implemented to establish real-world measurements
4. Volume calculation algorithm implemented using depth maps and detected scale
5. Cubic yard conversion implemented with configurable unit support
6. Confidence scoring system for volume estimates based on detection quality
7. User confirmation prompts for low-confidence estimates
8. Inference latency < 550ms for typical material photos (P95)
9. Model versioning and version tracking in estimation results
10. Output standardized with volume estimation response schema

---

## Dev Notes

### Architecture Context
- **Service Type**: Python FastAPI microservice with GPU inference support [Source: architecture.md#4.6.3-Volume-Estimation-Engine]
- **Priority**: P1 (Should-have) - Volume estimation is less critical than damage/material detection [Source: prd.md#6-Functional-Requirements]
- **Inference Infrastructure**: GPU instances (AWS EC2 P3/P4) for model serving
- **Model Serving**: TorchServe or TensorFlow Serving for production inference
- **Deployment**: Kubernetes with GPU node pools for auto-scaling [Source: architecture.md#10.2-Infrastructure-as-Code]

### Detection Engine Specifications
From architecture.md#4.6.3:
- **Capabilities**: Detect loose materials (gravel, mulch, sand); estimate volume in cubic yards
- **Depth Estimation**: Use depth maps and scale references for accurate volume calculation
- **Output**: Volume estimate, depth map, confidence score
- **Models**:
  - Depth Estimation: MiDaS or DPT (Dense Prediction Transformers)
  - Material Segmentation: U-Net or DeepLabv3
  - Scale Detection: Object detection model for reference objects

### Response Schema
**Output Format:**
```json
{
  "material": "gravel",
  "estimated_volume": 2.5,
  "unit": "cubic_yards",
  "confidence": 0.75,
  "requires_confirmation": true,
  "volume_range": {
    "min": 2.1,
    "max": 2.9
  },
  "depth_map": "s3://bucket/depth/photo123.png",
  "scale_reference": {
    "type": "person",
    "confidence": 0.82,
    "estimated_height_cm": 170
  },
  "calculation_method": "depth_map_scale_reference",
  "processing_time_ms": 520,
  "model_version": "volume-v1.0.0",
  "confidence_breakdown": {
    "depth_estimation": 0.88,
    "material_detection": 0.92,
    "scale_detection": 0.75
  }
}
```

### Model Details
**Depth Estimation Model (MiDaS/DPT):**
- Input: RGB images (arbitrary resolution)
- Output: Depth maps (normalized 0-1 values)
- Training: Trained on diverse depth estimation datasets
- Inference time: 200-300ms per image
- Relative depth accuracy without absolute scale reference

**Material Segmentation Model (U-Net/DeepLabv3):**
- Input: 512x512 RGB images
- Output: Pixel-level material mask
- Classes: gravel, mulch, sand, other, non-material
- Inference time: 100-150ms per image

**Scale Reference Detection (YOLOv8):**
- Input: RGB images
- Output: Bounding boxes for known reference objects
- Classes: person (standard height), measuring tape, wheel, car, etc.
- Inference time: 80-120ms per image

### Technical Implementation Details

**Volume Calculation Algorithm**: [Source: architecture.md#4.6.3-Volume-Estimation-Engine]
Steps:
1. Apply depth estimation to get depth map
2. Detect material boundaries using segmentation
3. Identify scale reference (person, measuring tape, etc.)
4. Establish scale: convert pixel depth to real-world units
5. Calculate material area in 3D space from segmentation mask
6. Integrate depth over material area to estimate volume
7. Convert to cubic yards (1 cubic yard = 27 cubic feet)

**Depth Map Processing**:
- Normalize depth values to reasonable range (e.g., 0-10 meters)
- Apply smoothing filters to reduce noise
- Crop to material area of interest
- Handle occlusions and missing depth data

**Scale Reference System**:
- Support multiple reference types: person (standard 170cm), measuring tape, known objects
- Person detection: Use face size + body proportion estimation
- Measuring tape: Detect tape markings and scale directly
- Fallback: Use camera intrinsics if available (from EXIF)
- Combine multiple scale references for higher confidence

**Confidence Scoring**:
- Depth estimation confidence (model output)
- Material segmentation confidence
- Scale reference detection confidence
- Combine as weighted average
- Flag estimates < 0.7 confidence for user confirmation

**Unit Conversion**:
- Support multiple units: cubic_yards, cubic_feet, cubic_meters, liters, gallons
- Configurable default unit based on region
- Include unit conversion functions
- Round estimates based on unit (e.g., nearest 0.1 cubic yard)

### File Structure
```
backend/src/
├── ai_models/
│   ├── volume_estimation/
│   │   ├── depth_estimator.py       # Depth estimation model
│   │   ├── material_segmenter.py    # Material segmentation
│   │   ├── scale_detector.py        # Scale reference detection
│   │   ├── volume_calculator.py     # Volume calculation logic
│   │   ├── pipeline.py              # End-to-end estimation pipeline
│   │   └── config.py                # Model configuration
│   └── model_loader.py              # Model loading and caching
├── services/
│   └── volume_estimation_service.py  # Service logic
├── schemas/
│   └── volume_estimation_schema.py   # Response schemas
└── api/
    └── volume_estimation_routes.py   # gRPC endpoints

backend/tests/
├── test_depth_estimator.py           # Depth model tests
├── test_material_segmentation.py     # Segmentation tests
├── test_scale_detector.py            # Scale detection tests
├── test_volume_calculator.py         # Volume calculation tests
└── test_volume_pipeline.py           # End-to-end pipeline tests

backend/data/
└── reference_objects.json            # Scale reference database
```

### Dependencies
- torch >= 2.0.0 with CUDA support
- timm (PyTorch Image Models) >= 0.6.0 for DPT and other models
- einops for tensor operations
- OpenCV >= 4.6 for image processing
- Pillow for image operations
- NumPy for numerical operations
- scikit-image for image processing algorithms
- ultralytics >= 8.0 for YOLOv8 (scale detection)
- boto3 for S3 operations (depth map storage)

### Integration Points
- **Input**: AI Orchestrator (gRPC) with photo URLs from S3
- **Output**: Volume estimation results to Orchestrator, depth maps to S3
- **Cache**: Redis for caching estimation results
- **Database**: PostgreSQL for storing reference object data
- **Monitoring**: Prometheus metrics for model performance

### Performance Targets
- **Inference Latency**: < 550ms P95 for typical material photos [Source: architecture.md#9.1-Performance-Targets]
- **Volume Accuracy**: Within 15-20% of actual volume (acceptable for estimation)
- **Throughput**: Support 50+ concurrent requests (lower than P0 engines)
- **GPU Utilization**: Target > 60% utilization

### Testing Standards
- **Test Framework**: pytest with GPU test fixtures
- **Unit Tests**: Model loading, preprocessing, volume calculation (>80% coverage)
- **Integration Tests**: End-to-end pipeline with real material photos
- **Performance Tests**: Latency benchmarking on various image sizes
- **Accuracy Tests**: Compare estimated volumes with known ground truth
- **Edge Case Tests**: Partial views, poor lighting, shadowing, multiple materials
- **Test Locations**: `/backend/tests/test_volume_*.py`
- **GPU Availability**: Tests should gracefully skip if GPU unavailable
- **Test Data**: Use sample photos with known material volumes
- **Test Execution**: `pytest backend/tests/test_volume_*.py -v --benchmark`

---

## Tasks / Subtasks

- [ ] Set up volume estimation service infrastructure (AC: 1, 9)
  - [ ] Create FastAPI service with health check endpoints
  - [ ] Implement model configuration management
  - [ ] Set up GPU memory management
  - [ ] Create model version tracking system
  - [ ] Add service logging with structured output

- [ ] Create scale reference database (AC: 4, 5)
  - [ ] Design reference object schema (person height, measuring tape, etc.)
  - [ ] Create reference object detection mapping
  - [ ] Implement reference object database loader
  - [ ] Add unit conversion functions (cubic yards, feet, meters)
  - [ ] Create calibration data for known reference objects
  - [ ] Unit tests for unit conversion

- [ ] Integrate depth estimation model (AC: 1)
  - [ ] Load pre-trained MiDaS or DPT model
  - [ ] Implement image preprocessing pipeline
  - [ ] Create depth map generation inference wrapper
  - [ ] Implement depth normalization and scaling
  - [ ] Add depth map visualization (save to S3)
  - [ ] Add inference latency tracking
  - [ ] Unit tests for depth estimation

- [ ] Integrate material segmentation model (AC: 2)
  - [ ] Load pre-trained U-Net or DeepLabv3 model
  - [ ] Implement segmentation preprocessing
  - [ ] Create segmentation inference wrapper
  - [ ] Implement post-processing to clean masks
  - [ ] Create material classification from segmentation
  - [ ] Unit tests for segmentation model

- [ ] Implement scale reference detection (AC: 4)
  - [ ] Load YOLOv8 model for reference object detection
  - [ ] Implement person detection and height estimation
  - [ ] Implement measuring tape detection (if supported)
  - [ ] Create scale calculation from detected reference
  - [ ] Implement fallback to camera intrinsics (EXIF)
  - [ ] Unit tests for scale detection

- [ ] Implement volume calculation algorithm (AC: 4, 5)
  - [ ] Create depth map normalization logic
  - [ ] Implement material area calculation from segmentation
  - [ ] Create volume integration algorithm (depth × area)
  - [ ] Implement scale conversion (pixel to real-world)
  - [ ] Create unit conversion (cubic feet to cubic yards)
  - [ ] Add handling for multiple material types
  - [ ] Unit tests for volume calculation
  - [ ] Accuracy validation against known volumes

- [ ] Implement confidence scoring system (AC: 6, 7)
  - [ ] Create confidence calculation from model outputs
  - [ ] Implement component confidence breakdown
  - [ ] Create weighted confidence combination
  - [ ] Implement low-confidence flagging for user confirmation
  - [ ] Add confidence threshold configuration
  - [ ] Unit tests for confidence scoring

- [ ] Implement volume range estimation (AC: 6)
  - [ ] Create uncertainty quantification logic
  - [ ] Calculate min/max volume bounds
  - [ ] Implement confidence interval calculation
  - [ ] Add sensitivity analysis for scale variations
  - [ ] Unit tests for range estimation

- [ ] Implement response schema and validation (AC: 10)
  - [ ] Create Pydantic models for volume estimation response
  - [ ] Implement response builder from model outputs
  - [ ] Add confidence breakdown generation
  - [ ] Create material type identification
  - [ ] Validate response schema compliance
  - [ ] Unit tests for response schema

- [ ] Implement GPU optimization and caching (AC: 8)
  - [ ] Load models on service startup
  - [ ] Implement model instance caching
  - [ ] Add GPU memory pre-allocation
  - [ ] Cache depth maps in Redis
  - [ ] Performance tests for latency benchmarking

- [ ] Implement image preprocessing pipeline
  - [ ] Handle EXIF orientation and metadata extraction
  - [ ] Normalize images to model input format
  - [ ] Implement resolution optimization
  - [ ] Add handling for various image formats
  - [ ] Extract camera intrinsics for depth scaling
  - [ ] Unit tests for preprocessing

- [ ] Implement gRPC service endpoints
  - [ ] Create gRPC proto definitions
  - [ ] Implement estimate_volume RPC method
  - [ ] Add health check gRPC method
  - [ ] Implement error handling and status codes
  - [ ] Integration tests for gRPC endpoints

- [ ] Implement monitoring and metrics
  - [ ] Create Prometheus metrics for inference latency
  - [ ] Track confidence score distribution
  - [ ] Monitor material type distribution
  - [ ] Track user confirmation rates
  - [ ] Create model version tracking in metrics
  - [ ] Add accuracy metrics (if ground truth available)

- [ ] Create comprehensive test suite (>80% coverage)
  - [ ] Unit tests for each model component
  - [ ] Integration tests for full pipeline
  - [ ] Performance benchmarking tests
  - [ ] Accuracy validation tests
  - [ ] Edge case tests (partial views, poor lighting)
  - [ ] Test fixtures with sample material photos
  - [ ] GPU-aware test skipping

- [ ] Documentation and deployment guides
  - [ ] API documentation for gRPC methods
  - [ ] Model deployment and versioning guide
  - [ ] Depth estimation algorithm explanation
  - [ ] Scale reference calibration guide
  - [ ] Troubleshooting guide for estimation issues
  - [ ] Accuracy expectations and limitations document

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-18 | 1.0 | Initial story creation for Volume Estimation Engine | Scrum Master |

---
